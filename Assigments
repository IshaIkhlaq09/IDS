# 18/09/23
# CSC461 – Assignment1 – Web Scraping 
# Isha Ikhlaq
# Sp20-BSE-009
# A brief description of the task
task 1:
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

# URLs of your favorite movies on IMDb
movie_urls = [
    'https://www.imdb.com/title/tt0111161/',    The Shawshank Redemption
    'https://www.imdb.com/title/tt0137523/',    Fight Club
    'https://www.imdb.com/title/tt0468569/',   The Dark Knight
    'https://www.imdb.com/title/tt0109830/',   Forrest Gump
    'https://www.imdb.com/title/tt0118799/'     Life Is Beautiful
]
titles = []
ratings = []

# Loop through the movie URLs and scrape data
for url in movie_urls:
    # Send a GET request to the IMDb URL
    response = requests.get(url)
    if response.status_code == 200:
        # Parse the HTML content of the page
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Extract movie title
        title = soup.find('div', class_='title_wrapper').h1.text.strip()
        
        # Extract movie rating
        rating = soup.find('span', itemprop='ratingValue').text.strip()
        
        # Append data to lists
        titles.append(title)
        ratings.append(rating)
        
        # Sleep for 1 second to avoid overloading IMDb's servers
        time.sleep(1)
    else:
        print(f"Failed to fetch data from {url}")

# DataFrame to store the scraped data
movie_data = pd.DataFrame({'Title': titles, 'Rating': ratings})

# Export the data to an Excel file
movie_data.to_excel('favorite_movies.xlsx', index=False)

print("Scraping and data export completed successfully!")

task#2:
import requests
from bs4 import BeautifulSoup



# the URL for the "Britannica" website
url_britannica = "https://www.britannica.com/on-this-day/Sep-09"

# Send an HTTP GET request to the "Britannica" URL with headers
page_britannica = requests.get(url_britannica, headers={"User-Agent": "Mozilla/5.0"})

# Parse the HTML content of the page
soup_britannica = BeautifulSoup(page_britannica.content, "html.parser")

# Find the container div for events
events_container = soup_britannica.find("div", class_="border-top py-30")

# Find all divs containing event details
event_divs = events_container.find_all("div", class_="card-body font-serif")

# Initialize an empty list to store event descriptions
events_descriptions = []

# Iterate through event divs and extract event descriptions
for event_div in event_divs:
    event_description = event_div.text.strip()
    events_descriptions.append(event_description)

# Print the events with proper numbering and formatting
print("Events on Sep-09 according to Britannica:\n")
for i, event_description in enumerate(events_descriptions, 1):
    print(f"{i}. {event_description}\n")

    # Define the URL for the "timeanddate" website
url_timeanddate = 'https://www.timeanddate.com/on-this-day/Sep-09'

print("Important events on my birthdate from 'timeanddate' website:\n")
event_page = requests.get(url_timeanddate, headers={"User-Agent": 'Mozilla/5.0'})
soup_event = BeautifulSoup(event_page.content, "html.parser")

# Find the event block container
event_block = soup_event.find("div", class_="otd-life__block")
event_list = event_block.find("ul")

# Initialize a list to store event names
event_names = []

# Find and extract event names
h3_events = event_list.find_all("h3")
for h3 in h3_events:
    event_name = h3.text.split(" ")[1]
    event_names.append(event_name)
    print(f"- {event_name}")

print("\n")
